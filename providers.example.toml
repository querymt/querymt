[[providers]]
name = "alibaba"
path = "oci://ghcr.io/querymt/alibaba:latest"

[[providers]]
name = "anthropic"
path = "oci://ghcr.io/querymt/anthropic:latest"

[[providers]]
name = "google"
path = "oci://ghcr.io/querymt/google:latest"

[[providers]]
name = "mistral"
path = "oci://ghcr.io/querymt/mistral:latest"

[[providers]]
name = "ollama"
path = "oci://ghcr.io/querymt/ollama:latest"

[[providers]]
name = "openai"
path = "oci://ghcr.io/querymt/openai:latest"

[[providers]]
name = "codex"
path = "oci://ghcr.io/querymt/codex:latest"

[[providers]]
name = "openrouter"
path = "oci://ghcr.io/querymt/openrouter:latest"

# Local GGUF via native llama.cpp plugin
[[providers]]
name = "llama_cpp"
path = "/path/to/libqmt_llama_cpp.dylib"
[providers.config]
model_path = "/path/to/model.gguf"
max_tokens = 256
